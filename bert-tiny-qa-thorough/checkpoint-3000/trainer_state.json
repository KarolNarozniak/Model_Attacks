{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 300.0,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 5.0,
      "grad_norm": 8.393054962158203,
      "learning_rate": 4.9755e-05,
      "loss": 5.6615,
      "step": 50
    },
    {
      "epoch": 10.0,
      "grad_norm": 9.425724029541016,
      "learning_rate": 4.9505e-05,
      "loss": 5.6239,
      "step": 100
    },
    {
      "epoch": 15.0,
      "grad_norm": 7.710037708282471,
      "learning_rate": 4.9255e-05,
      "loss": 5.5662,
      "step": 150
    },
    {
      "epoch": 20.0,
      "grad_norm": 10.135762214660645,
      "learning_rate": 4.9005e-05,
      "loss": 5.512,
      "step": 200
    },
    {
      "epoch": 25.0,
      "grad_norm": 7.87075138092041,
      "learning_rate": 4.8755e-05,
      "loss": 5.4481,
      "step": 250
    },
    {
      "epoch": 30.0,
      "grad_norm": 8.110613822937012,
      "learning_rate": 4.8505e-05,
      "loss": 5.3925,
      "step": 300
    },
    {
      "epoch": 35.0,
      "grad_norm": 13.020833015441895,
      "learning_rate": 4.8255e-05,
      "loss": 5.339,
      "step": 350
    },
    {
      "epoch": 40.0,
      "grad_norm": 8.850674629211426,
      "learning_rate": 4.8005e-05,
      "loss": 5.2933,
      "step": 400
    },
    {
      "epoch": 45.0,
      "grad_norm": 6.910409450531006,
      "learning_rate": 4.7755e-05,
      "loss": 5.2259,
      "step": 450
    },
    {
      "epoch": 50.0,
      "grad_norm": 14.743215560913086,
      "learning_rate": 4.7505e-05,
      "loss": 5.1669,
      "step": 500
    },
    {
      "epoch": 55.0,
      "grad_norm": 10.055549621582031,
      "learning_rate": 4.725500000000001e-05,
      "loss": 5.1164,
      "step": 550
    },
    {
      "epoch": 60.0,
      "grad_norm": 11.0491943359375,
      "learning_rate": 4.7005e-05,
      "loss": 5.0736,
      "step": 600
    },
    {
      "epoch": 65.0,
      "grad_norm": 9.38661003112793,
      "learning_rate": 4.6755e-05,
      "loss": 5.0047,
      "step": 650
    },
    {
      "epoch": 70.0,
      "grad_norm": 7.3871049880981445,
      "learning_rate": 4.6505e-05,
      "loss": 4.9393,
      "step": 700
    },
    {
      "epoch": 75.0,
      "grad_norm": 12.658346176147461,
      "learning_rate": 4.6255000000000004e-05,
      "loss": 4.8952,
      "step": 750
    },
    {
      "epoch": 80.0,
      "grad_norm": 7.616672039031982,
      "learning_rate": 4.6005000000000004e-05,
      "loss": 4.8513,
      "step": 800
    },
    {
      "epoch": 85.0,
      "grad_norm": 8.204994201660156,
      "learning_rate": 4.5755000000000005e-05,
      "loss": 4.7773,
      "step": 850
    },
    {
      "epoch": 90.0,
      "grad_norm": 11.006034851074219,
      "learning_rate": 4.5505000000000006e-05,
      "loss": 4.7286,
      "step": 900
    },
    {
      "epoch": 95.0,
      "grad_norm": 7.373813152313232,
      "learning_rate": 4.5255000000000006e-05,
      "loss": 4.6747,
      "step": 950
    },
    {
      "epoch": 100.0,
      "grad_norm": 7.880988121032715,
      "learning_rate": 4.5005e-05,
      "loss": 4.6242,
      "step": 1000
    },
    {
      "epoch": 105.0,
      "grad_norm": 10.634228706359863,
      "learning_rate": 4.4755e-05,
      "loss": 4.5642,
      "step": 1050
    },
    {
      "epoch": 110.0,
      "grad_norm": 10.2159423828125,
      "learning_rate": 4.4505e-05,
      "loss": 4.5215,
      "step": 1100
    },
    {
      "epoch": 115.0,
      "grad_norm": 9.84642505645752,
      "learning_rate": 4.4255e-05,
      "loss": 4.4635,
      "step": 1150
    },
    {
      "epoch": 120.0,
      "grad_norm": 9.086830139160156,
      "learning_rate": 4.4005e-05,
      "loss": 4.4151,
      "step": 1200
    },
    {
      "epoch": 125.0,
      "grad_norm": 10.400256156921387,
      "learning_rate": 4.3755000000000004e-05,
      "loss": 4.3669,
      "step": 1250
    },
    {
      "epoch": 130.0,
      "grad_norm": 9.35717487335205,
      "learning_rate": 4.3505000000000004e-05,
      "loss": 4.3272,
      "step": 1300
    },
    {
      "epoch": 135.0,
      "grad_norm": 8.864002227783203,
      "learning_rate": 4.3255e-05,
      "loss": 4.2649,
      "step": 1350
    },
    {
      "epoch": 140.0,
      "grad_norm": 9.36867618560791,
      "learning_rate": 4.3005e-05,
      "loss": 4.2181,
      "step": 1400
    },
    {
      "epoch": 145.0,
      "grad_norm": 10.881390571594238,
      "learning_rate": 4.2755e-05,
      "loss": 4.1773,
      "step": 1450
    },
    {
      "epoch": 150.0,
      "grad_norm": 7.685013771057129,
      "learning_rate": 4.2505e-05,
      "loss": 4.1263,
      "step": 1500
    },
    {
      "epoch": 155.0,
      "grad_norm": 10.480382919311523,
      "learning_rate": 4.2255e-05,
      "loss": 4.0791,
      "step": 1550
    },
    {
      "epoch": 160.0,
      "grad_norm": 8.168951988220215,
      "learning_rate": 4.2005e-05,
      "loss": 4.0282,
      "step": 1600
    },
    {
      "epoch": 165.0,
      "grad_norm": 9.395748138427734,
      "learning_rate": 4.1755e-05,
      "loss": 3.9907,
      "step": 1650
    },
    {
      "epoch": 170.0,
      "grad_norm": 9.60855484008789,
      "learning_rate": 4.1504999999999996e-05,
      "loss": 3.9464,
      "step": 1700
    },
    {
      "epoch": 175.0,
      "grad_norm": 17.897449493408203,
      "learning_rate": 4.1255e-05,
      "loss": 3.9038,
      "step": 1750
    },
    {
      "epoch": 180.0,
      "grad_norm": 13.012158393859863,
      "learning_rate": 4.1005000000000005e-05,
      "loss": 3.8499,
      "step": 1800
    },
    {
      "epoch": 185.0,
      "grad_norm": 8.503717422485352,
      "learning_rate": 4.0755000000000005e-05,
      "loss": 3.8107,
      "step": 1850
    },
    {
      "epoch": 190.0,
      "grad_norm": 10.65467643737793,
      "learning_rate": 4.0505000000000006e-05,
      "loss": 3.7725,
      "step": 1900
    },
    {
      "epoch": 195.0,
      "grad_norm": 11.774930953979492,
      "learning_rate": 4.025500000000001e-05,
      "loss": 3.7339,
      "step": 1950
    },
    {
      "epoch": 200.0,
      "grad_norm": 8.659831047058105,
      "learning_rate": 4.0005e-05,
      "loss": 3.6773,
      "step": 2000
    },
    {
      "epoch": 205.0,
      "grad_norm": 8.799386024475098,
      "learning_rate": 3.9755e-05,
      "loss": 3.6529,
      "step": 2050
    },
    {
      "epoch": 210.0,
      "grad_norm": 12.317842483520508,
      "learning_rate": 3.9505e-05,
      "loss": 3.5996,
      "step": 2100
    },
    {
      "epoch": 215.0,
      "grad_norm": 10.308722496032715,
      "learning_rate": 3.9255e-05,
      "loss": 3.5753,
      "step": 2150
    },
    {
      "epoch": 220.0,
      "grad_norm": 12.805733680725098,
      "learning_rate": 3.9005000000000003e-05,
      "loss": 3.5262,
      "step": 2200
    },
    {
      "epoch": 225.0,
      "grad_norm": 14.140299797058105,
      "learning_rate": 3.8755000000000004e-05,
      "loss": 3.486,
      "step": 2250
    },
    {
      "epoch": 230.0,
      "grad_norm": 11.372153282165527,
      "learning_rate": 3.8505000000000005e-05,
      "loss": 3.44,
      "step": 2300
    },
    {
      "epoch": 235.0,
      "grad_norm": 8.133174896240234,
      "learning_rate": 3.8255e-05,
      "loss": 3.4067,
      "step": 2350
    },
    {
      "epoch": 240.0,
      "grad_norm": 14.79932975769043,
      "learning_rate": 3.8005e-05,
      "loss": 3.3667,
      "step": 2400
    },
    {
      "epoch": 245.0,
      "grad_norm": 9.811325073242188,
      "learning_rate": 3.7755e-05,
      "loss": 3.321,
      "step": 2450
    },
    {
      "epoch": 250.0,
      "grad_norm": 11.847966194152832,
      "learning_rate": 3.7505e-05,
      "loss": 3.2932,
      "step": 2500
    },
    {
      "epoch": 255.0,
      "grad_norm": 10.281097412109375,
      "learning_rate": 3.7255e-05,
      "loss": 3.261,
      "step": 2550
    },
    {
      "epoch": 260.0,
      "grad_norm": 7.847837924957275,
      "learning_rate": 3.7005e-05,
      "loss": 3.2166,
      "step": 2600
    },
    {
      "epoch": 265.0,
      "grad_norm": 8.770550727844238,
      "learning_rate": 3.6755e-05,
      "loss": 3.1841,
      "step": 2650
    },
    {
      "epoch": 270.0,
      "grad_norm": 8.320383071899414,
      "learning_rate": 3.6505e-05,
      "loss": 3.145,
      "step": 2700
    },
    {
      "epoch": 275.0,
      "grad_norm": 11.598929405212402,
      "learning_rate": 3.6255e-05,
      "loss": 3.1032,
      "step": 2750
    },
    {
      "epoch": 280.0,
      "grad_norm": 12.09765338897705,
      "learning_rate": 3.6005e-05,
      "loss": 3.065,
      "step": 2800
    },
    {
      "epoch": 285.0,
      "grad_norm": 9.705727577209473,
      "learning_rate": 3.5755e-05,
      "loss": 3.0403,
      "step": 2850
    },
    {
      "epoch": 290.0,
      "grad_norm": 9.817005157470703,
      "learning_rate": 3.5505e-05,
      "loss": 3.0104,
      "step": 2900
    },
    {
      "epoch": 295.0,
      "grad_norm": 10.999141693115234,
      "learning_rate": 3.5255e-05,
      "loss": 2.975,
      "step": 2950
    },
    {
      "epoch": 300.0,
      "grad_norm": 15.679773330688477,
      "learning_rate": 3.5005e-05,
      "loss": 2.9404,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1000,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 30184691558400.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
