{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 700.0,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 5.0,
      "grad_norm": 8.393054962158203,
      "learning_rate": 4.9755e-05,
      "loss": 5.6615,
      "step": 50
    },
    {
      "epoch": 10.0,
      "grad_norm": 9.425724029541016,
      "learning_rate": 4.9505e-05,
      "loss": 5.6239,
      "step": 100
    },
    {
      "epoch": 15.0,
      "grad_norm": 7.710037708282471,
      "learning_rate": 4.9255e-05,
      "loss": 5.5662,
      "step": 150
    },
    {
      "epoch": 20.0,
      "grad_norm": 10.135762214660645,
      "learning_rate": 4.9005e-05,
      "loss": 5.512,
      "step": 200
    },
    {
      "epoch": 25.0,
      "grad_norm": 7.87075138092041,
      "learning_rate": 4.8755e-05,
      "loss": 5.4481,
      "step": 250
    },
    {
      "epoch": 30.0,
      "grad_norm": 8.110613822937012,
      "learning_rate": 4.8505e-05,
      "loss": 5.3925,
      "step": 300
    },
    {
      "epoch": 35.0,
      "grad_norm": 13.020833015441895,
      "learning_rate": 4.8255e-05,
      "loss": 5.339,
      "step": 350
    },
    {
      "epoch": 40.0,
      "grad_norm": 8.850674629211426,
      "learning_rate": 4.8005e-05,
      "loss": 5.2933,
      "step": 400
    },
    {
      "epoch": 45.0,
      "grad_norm": 6.910409450531006,
      "learning_rate": 4.7755e-05,
      "loss": 5.2259,
      "step": 450
    },
    {
      "epoch": 50.0,
      "grad_norm": 14.743215560913086,
      "learning_rate": 4.7505e-05,
      "loss": 5.1669,
      "step": 500
    },
    {
      "epoch": 55.0,
      "grad_norm": 10.055549621582031,
      "learning_rate": 4.725500000000001e-05,
      "loss": 5.1164,
      "step": 550
    },
    {
      "epoch": 60.0,
      "grad_norm": 11.0491943359375,
      "learning_rate": 4.7005e-05,
      "loss": 5.0736,
      "step": 600
    },
    {
      "epoch": 65.0,
      "grad_norm": 9.38661003112793,
      "learning_rate": 4.6755e-05,
      "loss": 5.0047,
      "step": 650
    },
    {
      "epoch": 70.0,
      "grad_norm": 7.3871049880981445,
      "learning_rate": 4.6505e-05,
      "loss": 4.9393,
      "step": 700
    },
    {
      "epoch": 75.0,
      "grad_norm": 12.658346176147461,
      "learning_rate": 4.6255000000000004e-05,
      "loss": 4.8952,
      "step": 750
    },
    {
      "epoch": 80.0,
      "grad_norm": 7.616672039031982,
      "learning_rate": 4.6005000000000004e-05,
      "loss": 4.8513,
      "step": 800
    },
    {
      "epoch": 85.0,
      "grad_norm": 8.204994201660156,
      "learning_rate": 4.5755000000000005e-05,
      "loss": 4.7773,
      "step": 850
    },
    {
      "epoch": 90.0,
      "grad_norm": 11.006034851074219,
      "learning_rate": 4.5505000000000006e-05,
      "loss": 4.7286,
      "step": 900
    },
    {
      "epoch": 95.0,
      "grad_norm": 7.373813152313232,
      "learning_rate": 4.5255000000000006e-05,
      "loss": 4.6747,
      "step": 950
    },
    {
      "epoch": 100.0,
      "grad_norm": 7.880988121032715,
      "learning_rate": 4.5005e-05,
      "loss": 4.6242,
      "step": 1000
    },
    {
      "epoch": 105.0,
      "grad_norm": 10.634228706359863,
      "learning_rate": 4.4755e-05,
      "loss": 4.5642,
      "step": 1050
    },
    {
      "epoch": 110.0,
      "grad_norm": 10.2159423828125,
      "learning_rate": 4.4505e-05,
      "loss": 4.5215,
      "step": 1100
    },
    {
      "epoch": 115.0,
      "grad_norm": 9.84642505645752,
      "learning_rate": 4.4255e-05,
      "loss": 4.4635,
      "step": 1150
    },
    {
      "epoch": 120.0,
      "grad_norm": 9.086830139160156,
      "learning_rate": 4.4005e-05,
      "loss": 4.4151,
      "step": 1200
    },
    {
      "epoch": 125.0,
      "grad_norm": 10.400256156921387,
      "learning_rate": 4.3755000000000004e-05,
      "loss": 4.3669,
      "step": 1250
    },
    {
      "epoch": 130.0,
      "grad_norm": 9.35717487335205,
      "learning_rate": 4.3505000000000004e-05,
      "loss": 4.3272,
      "step": 1300
    },
    {
      "epoch": 135.0,
      "grad_norm": 8.864002227783203,
      "learning_rate": 4.3255e-05,
      "loss": 4.2649,
      "step": 1350
    },
    {
      "epoch": 140.0,
      "grad_norm": 9.36867618560791,
      "learning_rate": 4.3005e-05,
      "loss": 4.2181,
      "step": 1400
    },
    {
      "epoch": 145.0,
      "grad_norm": 10.881390571594238,
      "learning_rate": 4.2755e-05,
      "loss": 4.1773,
      "step": 1450
    },
    {
      "epoch": 150.0,
      "grad_norm": 7.685013771057129,
      "learning_rate": 4.2505e-05,
      "loss": 4.1263,
      "step": 1500
    },
    {
      "epoch": 155.0,
      "grad_norm": 10.480382919311523,
      "learning_rate": 4.2255e-05,
      "loss": 4.0791,
      "step": 1550
    },
    {
      "epoch": 160.0,
      "grad_norm": 8.168951988220215,
      "learning_rate": 4.2005e-05,
      "loss": 4.0282,
      "step": 1600
    },
    {
      "epoch": 165.0,
      "grad_norm": 9.395748138427734,
      "learning_rate": 4.1755e-05,
      "loss": 3.9907,
      "step": 1650
    },
    {
      "epoch": 170.0,
      "grad_norm": 9.60855484008789,
      "learning_rate": 4.1504999999999996e-05,
      "loss": 3.9464,
      "step": 1700
    },
    {
      "epoch": 175.0,
      "grad_norm": 17.897449493408203,
      "learning_rate": 4.1255e-05,
      "loss": 3.9038,
      "step": 1750
    },
    {
      "epoch": 180.0,
      "grad_norm": 13.012158393859863,
      "learning_rate": 4.1005000000000005e-05,
      "loss": 3.8499,
      "step": 1800
    },
    {
      "epoch": 185.0,
      "grad_norm": 8.503717422485352,
      "learning_rate": 4.0755000000000005e-05,
      "loss": 3.8107,
      "step": 1850
    },
    {
      "epoch": 190.0,
      "grad_norm": 10.65467643737793,
      "learning_rate": 4.0505000000000006e-05,
      "loss": 3.7725,
      "step": 1900
    },
    {
      "epoch": 195.0,
      "grad_norm": 11.774930953979492,
      "learning_rate": 4.025500000000001e-05,
      "loss": 3.7339,
      "step": 1950
    },
    {
      "epoch": 200.0,
      "grad_norm": 8.659831047058105,
      "learning_rate": 4.0005e-05,
      "loss": 3.6773,
      "step": 2000
    },
    {
      "epoch": 205.0,
      "grad_norm": 8.799386024475098,
      "learning_rate": 3.9755e-05,
      "loss": 3.6529,
      "step": 2050
    },
    {
      "epoch": 210.0,
      "grad_norm": 12.317842483520508,
      "learning_rate": 3.9505e-05,
      "loss": 3.5996,
      "step": 2100
    },
    {
      "epoch": 215.0,
      "grad_norm": 10.308722496032715,
      "learning_rate": 3.9255e-05,
      "loss": 3.5753,
      "step": 2150
    },
    {
      "epoch": 220.0,
      "grad_norm": 12.805733680725098,
      "learning_rate": 3.9005000000000003e-05,
      "loss": 3.5262,
      "step": 2200
    },
    {
      "epoch": 225.0,
      "grad_norm": 14.140299797058105,
      "learning_rate": 3.8755000000000004e-05,
      "loss": 3.486,
      "step": 2250
    },
    {
      "epoch": 230.0,
      "grad_norm": 11.372153282165527,
      "learning_rate": 3.8505000000000005e-05,
      "loss": 3.44,
      "step": 2300
    },
    {
      "epoch": 235.0,
      "grad_norm": 8.133174896240234,
      "learning_rate": 3.8255e-05,
      "loss": 3.4067,
      "step": 2350
    },
    {
      "epoch": 240.0,
      "grad_norm": 14.79932975769043,
      "learning_rate": 3.8005e-05,
      "loss": 3.3667,
      "step": 2400
    },
    {
      "epoch": 245.0,
      "grad_norm": 9.811325073242188,
      "learning_rate": 3.7755e-05,
      "loss": 3.321,
      "step": 2450
    },
    {
      "epoch": 250.0,
      "grad_norm": 11.847966194152832,
      "learning_rate": 3.7505e-05,
      "loss": 3.2932,
      "step": 2500
    },
    {
      "epoch": 255.0,
      "grad_norm": 10.281097412109375,
      "learning_rate": 3.7255e-05,
      "loss": 3.261,
      "step": 2550
    },
    {
      "epoch": 260.0,
      "grad_norm": 7.847837924957275,
      "learning_rate": 3.7005e-05,
      "loss": 3.2166,
      "step": 2600
    },
    {
      "epoch": 265.0,
      "grad_norm": 8.770550727844238,
      "learning_rate": 3.6755e-05,
      "loss": 3.1841,
      "step": 2650
    },
    {
      "epoch": 270.0,
      "grad_norm": 8.320383071899414,
      "learning_rate": 3.6505e-05,
      "loss": 3.145,
      "step": 2700
    },
    {
      "epoch": 275.0,
      "grad_norm": 11.598929405212402,
      "learning_rate": 3.6255e-05,
      "loss": 3.1032,
      "step": 2750
    },
    {
      "epoch": 280.0,
      "grad_norm": 12.09765338897705,
      "learning_rate": 3.6005e-05,
      "loss": 3.065,
      "step": 2800
    },
    {
      "epoch": 285.0,
      "grad_norm": 9.705727577209473,
      "learning_rate": 3.5755e-05,
      "loss": 3.0403,
      "step": 2850
    },
    {
      "epoch": 290.0,
      "grad_norm": 9.817005157470703,
      "learning_rate": 3.5505e-05,
      "loss": 3.0104,
      "step": 2900
    },
    {
      "epoch": 295.0,
      "grad_norm": 10.999141693115234,
      "learning_rate": 3.5255e-05,
      "loss": 2.975,
      "step": 2950
    },
    {
      "epoch": 300.0,
      "grad_norm": 15.679773330688477,
      "learning_rate": 3.5005e-05,
      "loss": 2.9404,
      "step": 3000
    },
    {
      "epoch": 305.0,
      "grad_norm": 8.445709228515625,
      "learning_rate": 3.4755e-05,
      "loss": 2.9165,
      "step": 3050
    },
    {
      "epoch": 310.0,
      "grad_norm": 9.050514221191406,
      "learning_rate": 3.4505e-05,
      "loss": 2.8714,
      "step": 3100
    },
    {
      "epoch": 315.0,
      "grad_norm": 11.196428298950195,
      "learning_rate": 3.4255e-05,
      "loss": 2.848,
      "step": 3150
    },
    {
      "epoch": 320.0,
      "grad_norm": 9.313551902770996,
      "learning_rate": 3.4005000000000004e-05,
      "loss": 2.8172,
      "step": 3200
    },
    {
      "epoch": 325.0,
      "grad_norm": 11.157136917114258,
      "learning_rate": 3.3755000000000005e-05,
      "loss": 2.7809,
      "step": 3250
    },
    {
      "epoch": 330.0,
      "grad_norm": 10.29025936126709,
      "learning_rate": 3.3505000000000005e-05,
      "loss": 2.7516,
      "step": 3300
    },
    {
      "epoch": 335.0,
      "grad_norm": 12.203014373779297,
      "learning_rate": 3.3255000000000006e-05,
      "loss": 2.7208,
      "step": 3350
    },
    {
      "epoch": 340.0,
      "grad_norm": 13.710408210754395,
      "learning_rate": 3.3005e-05,
      "loss": 2.6875,
      "step": 3400
    },
    {
      "epoch": 345.0,
      "grad_norm": 9.22791576385498,
      "learning_rate": 3.2755e-05,
      "loss": 2.6671,
      "step": 3450
    },
    {
      "epoch": 350.0,
      "grad_norm": 12.120087623596191,
      "learning_rate": 3.2505e-05,
      "loss": 2.6378,
      "step": 3500
    },
    {
      "epoch": 355.0,
      "grad_norm": 9.72407341003418,
      "learning_rate": 3.2255e-05,
      "loss": 2.6004,
      "step": 3550
    },
    {
      "epoch": 360.0,
      "grad_norm": 11.038625717163086,
      "learning_rate": 3.2005e-05,
      "loss": 2.584,
      "step": 3600
    },
    {
      "epoch": 365.0,
      "grad_norm": 13.824413299560547,
      "learning_rate": 3.1755000000000003e-05,
      "loss": 2.5552,
      "step": 3650
    },
    {
      "epoch": 370.0,
      "grad_norm": 10.324895858764648,
      "learning_rate": 3.1505000000000004e-05,
      "loss": 2.5364,
      "step": 3700
    },
    {
      "epoch": 375.0,
      "grad_norm": 8.249894142150879,
      "learning_rate": 3.1255e-05,
      "loss": 2.4934,
      "step": 3750
    },
    {
      "epoch": 380.0,
      "grad_norm": 12.958876609802246,
      "learning_rate": 3.1005e-05,
      "loss": 2.484,
      "step": 3800
    },
    {
      "epoch": 385.0,
      "grad_norm": 8.111929893493652,
      "learning_rate": 3.0755e-05,
      "loss": 2.4296,
      "step": 3850
    },
    {
      "epoch": 390.0,
      "grad_norm": 9.665471076965332,
      "learning_rate": 3.0505e-05,
      "loss": 2.4266,
      "step": 3900
    },
    {
      "epoch": 395.0,
      "grad_norm": 10.473291397094727,
      "learning_rate": 3.0255e-05,
      "loss": 2.3831,
      "step": 3950
    },
    {
      "epoch": 400.0,
      "grad_norm": 13.089776992797852,
      "learning_rate": 3.0004999999999998e-05,
      "loss": 2.3712,
      "step": 4000
    },
    {
      "epoch": 405.0,
      "grad_norm": 10.410122871398926,
      "learning_rate": 2.9755e-05,
      "loss": 2.3394,
      "step": 4050
    },
    {
      "epoch": 410.0,
      "grad_norm": 8.364928245544434,
      "learning_rate": 2.9505e-05,
      "loss": 2.3255,
      "step": 4100
    },
    {
      "epoch": 415.0,
      "grad_norm": 10.132280349731445,
      "learning_rate": 2.9255e-05,
      "loss": 2.2697,
      "step": 4150
    },
    {
      "epoch": 420.0,
      "grad_norm": 13.001338005065918,
      "learning_rate": 2.9004999999999998e-05,
      "loss": 2.2722,
      "step": 4200
    },
    {
      "epoch": 425.0,
      "grad_norm": 8.387659072875977,
      "learning_rate": 2.8754999999999998e-05,
      "loss": 2.245,
      "step": 4250
    },
    {
      "epoch": 430.0,
      "grad_norm": 10.090023040771484,
      "learning_rate": 2.8505000000000002e-05,
      "loss": 2.2259,
      "step": 4300
    },
    {
      "epoch": 435.0,
      "grad_norm": 15.522010803222656,
      "learning_rate": 2.8255000000000003e-05,
      "loss": 2.1949,
      "step": 4350
    },
    {
      "epoch": 440.0,
      "grad_norm": 11.780797004699707,
      "learning_rate": 2.8005000000000004e-05,
      "loss": 2.18,
      "step": 4400
    },
    {
      "epoch": 445.0,
      "grad_norm": 10.044695854187012,
      "learning_rate": 2.7755000000000004e-05,
      "loss": 2.1415,
      "step": 4450
    },
    {
      "epoch": 450.0,
      "grad_norm": 10.59221363067627,
      "learning_rate": 2.7505000000000002e-05,
      "loss": 2.1244,
      "step": 4500
    },
    {
      "epoch": 455.0,
      "grad_norm": 10.297572135925293,
      "learning_rate": 2.7255000000000002e-05,
      "loss": 2.0945,
      "step": 4550
    },
    {
      "epoch": 460.0,
      "grad_norm": 8.658686637878418,
      "learning_rate": 2.7005000000000003e-05,
      "loss": 2.0891,
      "step": 4600
    },
    {
      "epoch": 465.0,
      "grad_norm": 10.10025405883789,
      "learning_rate": 2.6755000000000004e-05,
      "loss": 2.0509,
      "step": 4650
    },
    {
      "epoch": 470.0,
      "grad_norm": 10.580020904541016,
      "learning_rate": 2.6505e-05,
      "loss": 2.0461,
      "step": 4700
    },
    {
      "epoch": 475.0,
      "grad_norm": 8.668792724609375,
      "learning_rate": 2.6255000000000002e-05,
      "loss": 2.0115,
      "step": 4750
    },
    {
      "epoch": 480.0,
      "grad_norm": 8.942806243896484,
      "learning_rate": 2.6005000000000003e-05,
      "loss": 1.9975,
      "step": 4800
    },
    {
      "epoch": 485.0,
      "grad_norm": 10.44612979888916,
      "learning_rate": 2.5755e-05,
      "loss": 1.9925,
      "step": 4850
    },
    {
      "epoch": 490.0,
      "grad_norm": 9.658422470092773,
      "learning_rate": 2.5505e-05,
      "loss": 1.9514,
      "step": 4900
    },
    {
      "epoch": 495.0,
      "grad_norm": 12.331379890441895,
      "learning_rate": 2.5255e-05,
      "loss": 1.9425,
      "step": 4950
    },
    {
      "epoch": 500.0,
      "grad_norm": 15.088716506958008,
      "learning_rate": 2.5005000000000002e-05,
      "loss": 1.9169,
      "step": 5000
    },
    {
      "epoch": 505.0,
      "grad_norm": 12.091277122497559,
      "learning_rate": 2.4755e-05,
      "loss": 1.9074,
      "step": 5050
    },
    {
      "epoch": 510.0,
      "grad_norm": 8.89554214477539,
      "learning_rate": 2.4505e-05,
      "loss": 1.8675,
      "step": 5100
    },
    {
      "epoch": 515.0,
      "grad_norm": 12.731354713439941,
      "learning_rate": 2.4255e-05,
      "loss": 1.8789,
      "step": 5150
    },
    {
      "epoch": 520.0,
      "grad_norm": 14.756427764892578,
      "learning_rate": 2.4005e-05,
      "loss": 1.854,
      "step": 5200
    },
    {
      "epoch": 525.0,
      "grad_norm": 8.748194694519043,
      "learning_rate": 2.3755000000000002e-05,
      "loss": 1.825,
      "step": 5250
    },
    {
      "epoch": 530.0,
      "grad_norm": 7.276079177856445,
      "learning_rate": 2.3505000000000003e-05,
      "loss": 1.8164,
      "step": 5300
    },
    {
      "epoch": 535.0,
      "grad_norm": 7.464695930480957,
      "learning_rate": 2.3255e-05,
      "loss": 1.8052,
      "step": 5350
    },
    {
      "epoch": 540.0,
      "grad_norm": 12.911529541015625,
      "learning_rate": 2.3005e-05,
      "loss": 1.7882,
      "step": 5400
    },
    {
      "epoch": 545.0,
      "grad_norm": 9.714004516601562,
      "learning_rate": 2.2755e-05,
      "loss": 1.7588,
      "step": 5450
    },
    {
      "epoch": 550.0,
      "grad_norm": 7.106916904449463,
      "learning_rate": 2.2505000000000002e-05,
      "loss": 1.7418,
      "step": 5500
    },
    {
      "epoch": 555.0,
      "grad_norm": 12.113973617553711,
      "learning_rate": 2.2255e-05,
      "loss": 1.7353,
      "step": 5550
    },
    {
      "epoch": 560.0,
      "grad_norm": 11.256997108459473,
      "learning_rate": 2.2005e-05,
      "loss": 1.7146,
      "step": 5600
    },
    {
      "epoch": 565.0,
      "grad_norm": 10.490066528320312,
      "learning_rate": 2.1755e-05,
      "loss": 1.685,
      "step": 5650
    },
    {
      "epoch": 570.0,
      "grad_norm": 10.190666198730469,
      "learning_rate": 2.1505e-05,
      "loss": 1.6831,
      "step": 5700
    },
    {
      "epoch": 575.0,
      "grad_norm": 9.16091537475586,
      "learning_rate": 2.1255e-05,
      "loss": 1.698,
      "step": 5750
    },
    {
      "epoch": 580.0,
      "grad_norm": 10.968718528747559,
      "learning_rate": 2.1005e-05,
      "loss": 1.6397,
      "step": 5800
    },
    {
      "epoch": 585.0,
      "grad_norm": 8.142311096191406,
      "learning_rate": 2.0755000000000004e-05,
      "loss": 1.6255,
      "step": 5850
    },
    {
      "epoch": 590.0,
      "grad_norm": 9.284820556640625,
      "learning_rate": 2.0505e-05,
      "loss": 1.6479,
      "step": 5900
    },
    {
      "epoch": 595.0,
      "grad_norm": 15.40074348449707,
      "learning_rate": 2.0255000000000002e-05,
      "loss": 1.6231,
      "step": 5950
    },
    {
      "epoch": 600.0,
      "grad_norm": 13.260167121887207,
      "learning_rate": 2.0005000000000002e-05,
      "loss": 1.6103,
      "step": 6000
    },
    {
      "epoch": 605.0,
      "grad_norm": 11.087080955505371,
      "learning_rate": 1.9755e-05,
      "loss": 1.5684,
      "step": 6050
    },
    {
      "epoch": 610.0,
      "grad_norm": 9.758094787597656,
      "learning_rate": 1.9505e-05,
      "loss": 1.5712,
      "step": 6100
    },
    {
      "epoch": 615.0,
      "grad_norm": 7.569861888885498,
      "learning_rate": 1.9255e-05,
      "loss": 1.5732,
      "step": 6150
    },
    {
      "epoch": 620.0,
      "grad_norm": 7.073434829711914,
      "learning_rate": 1.9005000000000002e-05,
      "loss": 1.5402,
      "step": 6200
    },
    {
      "epoch": 625.0,
      "grad_norm": 10.511855125427246,
      "learning_rate": 1.8755e-05,
      "loss": 1.5477,
      "step": 6250
    },
    {
      "epoch": 630.0,
      "grad_norm": 14.876652717590332,
      "learning_rate": 1.8505e-05,
      "loss": 1.5475,
      "step": 6300
    },
    {
      "epoch": 635.0,
      "grad_norm": 7.014512062072754,
      "learning_rate": 1.8255e-05,
      "loss": 1.5088,
      "step": 6350
    },
    {
      "epoch": 640.0,
      "grad_norm": 11.181344032287598,
      "learning_rate": 1.8005e-05,
      "loss": 1.4927,
      "step": 6400
    },
    {
      "epoch": 645.0,
      "grad_norm": 7.8683180809021,
      "learning_rate": 1.7755000000000002e-05,
      "loss": 1.4888,
      "step": 6450
    },
    {
      "epoch": 650.0,
      "grad_norm": 8.214714050292969,
      "learning_rate": 1.7505000000000003e-05,
      "loss": 1.438,
      "step": 6500
    },
    {
      "epoch": 655.0,
      "grad_norm": 12.439080238342285,
      "learning_rate": 1.7255000000000003e-05,
      "loss": 1.4564,
      "step": 6550
    },
    {
      "epoch": 660.0,
      "grad_norm": 11.171002388000488,
      "learning_rate": 1.7005e-05,
      "loss": 1.458,
      "step": 6600
    },
    {
      "epoch": 665.0,
      "grad_norm": 12.784934997558594,
      "learning_rate": 1.6755e-05,
      "loss": 1.4273,
      "step": 6650
    },
    {
      "epoch": 670.0,
      "grad_norm": 13.642205238342285,
      "learning_rate": 1.6505000000000002e-05,
      "loss": 1.4471,
      "step": 6700
    },
    {
      "epoch": 675.0,
      "grad_norm": 10.116741180419922,
      "learning_rate": 1.6255e-05,
      "loss": 1.4071,
      "step": 6750
    },
    {
      "epoch": 680.0,
      "grad_norm": 8.274358749389648,
      "learning_rate": 1.6005e-05,
      "loss": 1.407,
      "step": 6800
    },
    {
      "epoch": 685.0,
      "grad_norm": 7.923829555511475,
      "learning_rate": 1.5755e-05,
      "loss": 1.4056,
      "step": 6850
    },
    {
      "epoch": 690.0,
      "grad_norm": 13.371748924255371,
      "learning_rate": 1.5505e-05,
      "loss": 1.3936,
      "step": 6900
    },
    {
      "epoch": 695.0,
      "grad_norm": 11.999014854431152,
      "learning_rate": 1.5255e-05,
      "loss": 1.3936,
      "step": 6950
    },
    {
      "epoch": 700.0,
      "grad_norm": 9.357315063476562,
      "learning_rate": 1.5005e-05,
      "loss": 1.373,
      "step": 7000
    }
  ],
  "logging_steps": 50,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1000,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 70430946969600.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
