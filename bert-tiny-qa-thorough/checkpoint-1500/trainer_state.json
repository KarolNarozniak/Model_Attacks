{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 150.0,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 5.0,
      "grad_norm": 8.393054962158203,
      "learning_rate": 4.9755e-05,
      "loss": 5.6615,
      "step": 50
    },
    {
      "epoch": 10.0,
      "grad_norm": 9.425724029541016,
      "learning_rate": 4.9505e-05,
      "loss": 5.6239,
      "step": 100
    },
    {
      "epoch": 15.0,
      "grad_norm": 7.710037708282471,
      "learning_rate": 4.9255e-05,
      "loss": 5.5662,
      "step": 150
    },
    {
      "epoch": 20.0,
      "grad_norm": 10.135762214660645,
      "learning_rate": 4.9005e-05,
      "loss": 5.512,
      "step": 200
    },
    {
      "epoch": 25.0,
      "grad_norm": 7.87075138092041,
      "learning_rate": 4.8755e-05,
      "loss": 5.4481,
      "step": 250
    },
    {
      "epoch": 30.0,
      "grad_norm": 8.110613822937012,
      "learning_rate": 4.8505e-05,
      "loss": 5.3925,
      "step": 300
    },
    {
      "epoch": 35.0,
      "grad_norm": 13.020833015441895,
      "learning_rate": 4.8255e-05,
      "loss": 5.339,
      "step": 350
    },
    {
      "epoch": 40.0,
      "grad_norm": 8.850674629211426,
      "learning_rate": 4.8005e-05,
      "loss": 5.2933,
      "step": 400
    },
    {
      "epoch": 45.0,
      "grad_norm": 6.910409450531006,
      "learning_rate": 4.7755e-05,
      "loss": 5.2259,
      "step": 450
    },
    {
      "epoch": 50.0,
      "grad_norm": 14.743215560913086,
      "learning_rate": 4.7505e-05,
      "loss": 5.1669,
      "step": 500
    },
    {
      "epoch": 55.0,
      "grad_norm": 10.055549621582031,
      "learning_rate": 4.725500000000001e-05,
      "loss": 5.1164,
      "step": 550
    },
    {
      "epoch": 60.0,
      "grad_norm": 11.0491943359375,
      "learning_rate": 4.7005e-05,
      "loss": 5.0736,
      "step": 600
    },
    {
      "epoch": 65.0,
      "grad_norm": 9.38661003112793,
      "learning_rate": 4.6755e-05,
      "loss": 5.0047,
      "step": 650
    },
    {
      "epoch": 70.0,
      "grad_norm": 7.3871049880981445,
      "learning_rate": 4.6505e-05,
      "loss": 4.9393,
      "step": 700
    },
    {
      "epoch": 75.0,
      "grad_norm": 12.658346176147461,
      "learning_rate": 4.6255000000000004e-05,
      "loss": 4.8952,
      "step": 750
    },
    {
      "epoch": 80.0,
      "grad_norm": 7.616672039031982,
      "learning_rate": 4.6005000000000004e-05,
      "loss": 4.8513,
      "step": 800
    },
    {
      "epoch": 85.0,
      "grad_norm": 8.204994201660156,
      "learning_rate": 4.5755000000000005e-05,
      "loss": 4.7773,
      "step": 850
    },
    {
      "epoch": 90.0,
      "grad_norm": 11.006034851074219,
      "learning_rate": 4.5505000000000006e-05,
      "loss": 4.7286,
      "step": 900
    },
    {
      "epoch": 95.0,
      "grad_norm": 7.373813152313232,
      "learning_rate": 4.5255000000000006e-05,
      "loss": 4.6747,
      "step": 950
    },
    {
      "epoch": 100.0,
      "grad_norm": 7.880988121032715,
      "learning_rate": 4.5005e-05,
      "loss": 4.6242,
      "step": 1000
    },
    {
      "epoch": 105.0,
      "grad_norm": 10.634228706359863,
      "learning_rate": 4.4755e-05,
      "loss": 4.5642,
      "step": 1050
    },
    {
      "epoch": 110.0,
      "grad_norm": 10.2159423828125,
      "learning_rate": 4.4505e-05,
      "loss": 4.5215,
      "step": 1100
    },
    {
      "epoch": 115.0,
      "grad_norm": 9.84642505645752,
      "learning_rate": 4.4255e-05,
      "loss": 4.4635,
      "step": 1150
    },
    {
      "epoch": 120.0,
      "grad_norm": 9.086830139160156,
      "learning_rate": 4.4005e-05,
      "loss": 4.4151,
      "step": 1200
    },
    {
      "epoch": 125.0,
      "grad_norm": 10.400256156921387,
      "learning_rate": 4.3755000000000004e-05,
      "loss": 4.3669,
      "step": 1250
    },
    {
      "epoch": 130.0,
      "grad_norm": 9.35717487335205,
      "learning_rate": 4.3505000000000004e-05,
      "loss": 4.3272,
      "step": 1300
    },
    {
      "epoch": 135.0,
      "grad_norm": 8.864002227783203,
      "learning_rate": 4.3255e-05,
      "loss": 4.2649,
      "step": 1350
    },
    {
      "epoch": 140.0,
      "grad_norm": 9.36867618560791,
      "learning_rate": 4.3005e-05,
      "loss": 4.2181,
      "step": 1400
    },
    {
      "epoch": 145.0,
      "grad_norm": 10.881390571594238,
      "learning_rate": 4.2755e-05,
      "loss": 4.1773,
      "step": 1450
    },
    {
      "epoch": 150.0,
      "grad_norm": 7.685013771057129,
      "learning_rate": 4.2505e-05,
      "loss": 4.1263,
      "step": 1500
    }
  ],
  "logging_steps": 50,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1000,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 15092345779200.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
